[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Water reuse, data science, risk characterization, community engagement",
    "section": "",
    "text": "Sean Thimons is a Physical Scientist at the U.S. Environmental Protection Agency, focusing on chemical risk assessment for oil and gas wastewater, industrial wastewater, and water reuse. His research aims to enhance wastewater characterization for reuse, prioritize emerging wastewater compounds, and develop rapid chemical risk evaluation methods using high-throughput data.\nThimons holds an M.S. in Water Resources, Science & Technology from Texas A&M University – San Antonio, where his thesis explored advanced treatment methods for hypersaline brines and oil/gas waste streams.\nThimons’ projects include supporting the EPA’s Strategic Research Action Plans (StRAP), focusing on risk characterization for water reuse, data curation for chemical safety, and technical assistance for drinking water projects. He has developed applications for lead service-line inventory validation and site prioritization for water quality analysis. His work with the New Mexico Produced Water Research Consortium involves developing risk-based workflows for assessing treated produced water for reuse.\nHis technical contributions extend to tools like the CompTox Chemistry Dashboard, Cheminformatics Toolbox, and ECOTOX Knowledgebase, enhancing analysis capabilities for thousands of compounds.\nHe also volunteers as a data scientist for a volunteer-research group focused on reducing homelessness utilizing machine learning and artificial intelligence."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Water reuse, data science, risk characterization, community engagement",
    "section": "Education",
    "text": "Education\n\n2021, M.S., Water Resources, Science & Technology, Texas A&M University – San Antonio\n2019, B.S., Biology, Texas A&M University – San Antonio"
  },
  {
    "objectID": "index.html#selected-work-experience",
    "href": "index.html#selected-work-experience",
    "title": "Water reuse, data science, risk characterization, community engagement",
    "section": "Selected Work Experience",
    "text": "Selected Work Experience\n\nPresent - 2025: Physical Scientist, U.S. EPA Office of Water, Office of Wastewater Management, Water Infrastructure Division, Clean Water Technology and Analytics Branch\n2025 - 2025: Physical Scientist, U.S. EPA Office of Research and Development, Center for Environmental Solutions and Emergency Response\n2021 - 2025: ORISE Research Fellow, U.S. EPA Office of Research and Development, Center for Environmental Solutions and Emergency Response"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects, Technical Support, Publications",
    "section": "",
    "text": "EPA-ORD Strategic Research Planning Support:\n\nSafe and Sustainable Water Resources: 406.1: Risk Characterization to inform fit-for-purpose water use.\nChemical Safety for Sustainability: 407.1: Generate and curate data relevant to chemical substances, structures, samples, and properties.\nChemical Safety for Sustainability: 408.3: Cross-disciplinary integration and applied case studies to support chemical safety decision making."
  },
  {
    "objectID": "projects.html#current-research-projects",
    "href": "projects.html#current-research-projects",
    "title": "Projects, Technical Support, Publications",
    "section": "",
    "text": "EPA-ORD Strategic Research Planning Support:\n\nSafe and Sustainable Water Resources: 406.1: Risk Characterization to inform fit-for-purpose water use.\nChemical Safety for Sustainability: 407.1: Generate and curate data relevant to chemical substances, structures, samples, and properties.\nChemical Safety for Sustainability: 408.3: Cross-disciplinary integration and applied case studies to support chemical safety decision making."
  },
  {
    "objectID": "projects.html#fun-things-i-work-on",
    "href": "projects.html#fun-things-i-work-on",
    "title": "Projects, Technical Support, Publications",
    "section": "Fun things I work on:",
    "text": "Fun things I work on:\n\nComptoxR : R package designed to interface with various US EPA API products for chemcial risk evaluation.\nCuration work : various R scripts and workflows that I use to grab data to build into relevant datasets.\nTHREAT : R Shiny application that leverages CompToxR and databases built out from various curation work to allow for users to cross-walk observational data against relevant benchmarks for environmental water quality."
  },
  {
    "objectID": "projects.html#technical-support",
    "href": "projects.html#technical-support",
    "title": "Projects, Technical Support, Publications",
    "section": "Technical Support",
    "text": "Technical Support\n\nRegion 8 RARE project: Evaluation of Produced Water Intended for Beneficial Reuse in Multiple Oil and Gas Basins. Stakeholders include EPA’s Region 3 and 6, US Department of Energy’s National Energy Technology Laboratory, and US EPA ORD-CCTE/CEMM\n\nFront-end R Shiny application development for site prioritization utilizing field and experimental data for acute, chronic, and cumulative toxicological evaluation.\n\nNew Mexico Produced Water Research Consortium’s Risk and Toxicology work group (workgroup lead), the Multi-State Coordination Counsel, and the Water-Portal and Data Management work group.\n\nDevelopment of risk-based workflow to assess acute and chronic potential across human and ecological receptors and determine potential for fit-for-purpose usage of treated produced water.\n\nPotable Water Reuse in Protein Production and Processing, Collaborative partnership of Tyson Foods, University of Nebraska, and the United States Department of Agriculture\nEvaluating the Microbial and Chemical Quality of Air Handler Unit Condensate, US EPA project\nIntegrated Performance Framework for Emerging Contaminants in Wastewater Treatment Plants, US EPA project\nTechnical support for New Mexico State University’s Non-Targeted Analysis and Whole Effluent Toxicity testing efforts for produced water to assess acute and chronic effects of exposure.\nTechnical support for SSWR.411.3 : BIL/IIJA Funded Technical Assistance Projects to Support the Drinking Water State Revolving Fund\n\nFront-end R Shiny application development utilizing EJScreen and machine-learning models for site prioritization"
  },
  {
    "objectID": "projects.html#selected-awards-and-professional-experience",
    "href": "projects.html#selected-awards-and-professional-experience",
    "title": "Projects, Technical Support, Publications",
    "section": "Selected Awards and Professional Experience",
    "text": "Selected Awards and Professional Experience\n\nNew Mexico Produced Water Research Consortium\nUS EPA Shooting Start Award: “Region 8 is grateful for your work organizing and analyzing our produced water data”"
  },
  {
    "objectID": "projects.html#publications",
    "href": "projects.html#publications",
    "title": "Projects, Technical Support, Publications",
    "section": "Publications",
    "text": "Publications\n\n\n\nDelanka-Pedige, Himali M. K., Robert B. Young, Maha T. Abutokaikah, Lin Chen, Huiyao Wang, Kanchana A. B. I. Imihamillage, Sean Thimons, et al. 2024. “Non-Targeted Analysis and Toxicity Prediction for Evaluation of Photocatalytic Membrane Distillation Removing Organic Contaminants from Hypersaline Oil and Gas Field-Produced Water.” Journal of Hazardous Materials 471 (June): 134436. https://doi.org/10.1016/j.jhazmat.2024.134436.\n\n\nSchoen, Mary E., Jay Garland, Jeffrey A. Soller, Sean X. Thimons, and Michael A. Jahne. 2023. “Onsite Nonpotable Water Systems Pathogen Treatment Targets: A Comparison of Infection and Disability-Adjusted Life Years (DALYs) Risk Benchmark Approaches.” Environmental Science & Technology 57 (26): 9559–66. https://doi.org/10.1021/acs.est.3c01152.\n\n\nThimons, Sean. 2021. “Treatment of Produced Water Using Ferrate (VI) and Directional Solvent Extraction,” 101.\n\n\nThimons, Sean, Shray Saxena, and Walter Den. 2022. “Ferrate-Pretreated Directional Solvent Extraction for Hydraulic Fracturing Produced Water: Technical and Economic Feasibility Studies.” Journal of Water Process Engineering 49 (October): 103053. https://doi.org/10.1016/j.jwpe.2022.103053."
  },
  {
    "objectID": "projects.html#presentations-posters-and-panels",
    "href": "projects.html#presentations-posters-and-panels",
    "title": "Projects, Technical Support, Publications",
    "section": "Presentations, Posters, and Panels",
    "text": "Presentations, Posters, and Panels\nDavis, C., Butler, J., Redman, A., Danforth, C., Thimons, S., Jahne, M., Xu, P. “Towards a Transparent Framework for Risk-based Evaluation of Treated Produced Water in the Permian.” SETAC North America 44th Annual Meeting, November 12–16, 2023, Louisville, KY.\nJahne, M., King, D., Kovalcik, K., Donohue, M., Pfaller, S., Helmick, K., Eades, G., Pait, M., Nye, M., Thimons, S., and Garland, J. “Water Quality Assessment of AC Condensate for Onsite Collection and Use.” 2023 WateReuse Symposium, March 5–8, 2023, Atlanta, GA.\nSchoen, M., Jahne, M., Soller, J., Garland, J., and Thimons, S. “Updated Pathogen Log-Reduction Targets for Onsite Non-Potable Water Reuse.” 2023 WateReuse Symposium, March 5–8, 2023, Atlanta, GA.\nThimons, S., Danforth, C., Xu, P., Butler, J., and Jahne, M. “Risk-Based Guidance for Treated Produced Water Reuse - Progress and Opportunities.” 2023 WateReuse Symposium, March 5–8, 2023, Atlanta, GA.\nHightower, M., Reible, D., Rosenblum, J., Stringfellow, W., and Thimons, S. Panel on State Produced Water Treatment and Reuse Approaches, 2023 WateReuse Symposium, March 5–8, 2023\nThimons, S.. Development and Implementation of a Quantitative Hazard, Risk, and Toxicological Evaluation Tool (QHRTET) for Regionally Focused Issues. Presented at Annual Meeting of the New Mexico Produced Water Research Consortium, Las Cruces, NM, USA, Dec 6-7, 2022.\nThimons, S., Saxena, S., Den, W., Treatment and desalination of hydraulic fracturing produced water using ferrate and directional solvent extraction. Presented at ACS Fall 2021, Atlanta, GA, August 22-26, 2021\nThimons, S.X., K.R. Cradock, and M.M.F. Lutnesky, Preliminary Characterization of Fish Survivorship in Backwater Pools on the Pecos River, NM USA. Joint meeting of Ichthyologists and Herpetologists (American Society of Ichthyologists and Herpetologists), Snowbird, UT, 2019"
  },
  {
    "objectID": "posts/1970-01-01/index.html",
    "href": "posts/1970-01-01/index.html",
    "title": "My First Post",
    "section": "",
    "text": "This is my first post on this new blog. Here I will be sharing updates on my projects, research, and other interests.\nStay tuned for more!"
  },
  {
    "objectID": "posts/2025-11-04/2025-11-04.html",
    "href": "posts/2025-11-04/2025-11-04.html",
    "title": "Tidy Tuesday 2025-11-04: Lead concentration in Flint water samples in 2015",
    "section": "",
    "text": "From TidyTuesday repository.\n\nThis week we are exploring lead levels in water samples collected in Flint, Michigan in 2015. The data comes from a paper by Loux and Gibson (2018) who advocate for using this data as a teaching example in introductory statistics courses.\nThe Flint lead data provide a compelling example for introducing students to simple univariate descriptive statistics. In addition, they provide examples for discussion of sampling and data collection, as well as ethical data handling.\nThe data this week includes samples collected by the Michigan Department of Environment (MDEQ) and data from a citizen science project coordinated by Prof Marc Edwards and colleagues at Virginia Tech. Community-sourced samples were collected after concerns were raised about the MDEQ excluding samples from their data. You can read about the “murky” story behind this data here.\nThank you to @nzgwynn for submitting this dataset in #23!\n\nHow does the distribution of lead levels differ between MDEQ and Virginia Tech datasets?\nHow do key statistics (mean, median, 90th percentile) change with/without excluded samples in the MDEQ sample?\n\n\n\n\nMy handy booster pack that allows me to install (if needed) and load my usual and favorite packages, as well as some helpful functions.\n\n\nCode\n# Packages ----------------------------------------------------------------\n\n{\n  # Install pak if it's not already installed\n  if (!requireNamespace(\"pak\", quietly = TRUE)) {\n    install.packages(\n      \"pak\",\n      repos = sprintf(\n        \"https://r-lib.github.io/p/pak/stable/%s/%s/%s\",\n        .Platform$pkgType,\n        R.Version()$os,\n        R.Version()$arch\n      )\n    )\n  }\n\n  # CRAN Packages ----\n  install_booster_pack &lt;- function(package, load = TRUE) {\n    # Loop through each package\n    for (pkg in package) {\n      # Check if the package is installed\n      if (!requireNamespace(pkg, quietly = TRUE)) {\n        # If not installed, install the package\n        pak::pkg_install(pkg)\n      }\n      # Load the package\n      if (load) {\n        library(pkg, character.only = TRUE)\n      }\n    }\n  }\n\n  if (file.exists('packages.txt')) {\n    packages &lt;- read.table('packages.txt')\n\n    install_booster_pack(package = packages$Package, load = FALSE)\n\n    rm(packages)\n  } else {\n    ## Packages ----\n\n    booster_pack &lt;- c(\n      ### IO ----\n      'fs',\n      'here',\n      'janitor',\n      'rio',\n      'tidyverse',\n      # 'data.table',\n      # 'mirai',\n      # 'targets',\n      # 'crew',\n\n      ### DB ----\n      # 'arrow',\n      # 'nanoparquet',\n      # 'duckdb',\n      # 'duckplyr',\n      # 'dbplyr',\n\n      ### EDA ----\n      'skimr',\n\n      ### Web ----\n      # 'rvest',\n      # 'polite',\n      # 'plumber',\n      # 'plumber2', #Still experimental\n      # 'httr2',\n\n      ### Plot ----\n      # 'paletteer',\n      # 'ragg',\n      'camcorder',\n      'esquisse',\n      # 'geofacet',\n      # 'patchwork',\n      # 'ggpubr', # Alternative to patchwork\n      # 'marquee',\n      # 'ggiraph',\n      # 'geomtextpath',\n      # 'ggpattern',\n      # 'ggbump',\n      # 'gghighlight',\n      # 'ggdist',\n      # 'ggforce',\n      # 'gghalves',\n      # 'ggtext',\n      # 'ggrepel', # Suggested for non-overlapping labels\n      # 'gganimate', # Suggested for animations\n      # 'ggsignif',\n      # 'ggTimeSeries',\n      # 'tidyheatmaps',\n      # 'ggdendro',\n      'ggstatsplot',\n\n      ### Modeling ----\n      'tidymodels',\n\n      ### Shiny ----\n      # 'shiny',\n      # 'bslib',\n      # 'DT',\n      # 'plotly',\n\n      ### Reporting ----\n      # 'quarto',\n      'gt',\n      'gtsummary',\n\n      ### Spatial ----\n      # 'sf',\n      # 'geoarrow',\n      # 'duckdbfs',\n      # 'duckspatial',\n      # 'ducksf',\n      # 'tidycensus', # Needs API\n      # 'mapgl',\n      # 'dataRetrieval', # Needs API\n      # 'StreamCatTools',\n\n      ### Misc ----\n      'tidytuesdayR'\n      # 'devtools',\n      # 'usethis',\n      # 'remotes'\n    )\n\n    # ! Change load flag to load packages\n    install_booster_pack(package = booster_pack, load = TRUE)\n    rm(install_booster_pack, booster_pack)\n  }\n\n  # GitHub Packages ----\n  # github_packages &lt;- c(\n  #     \"seanthimons/ComptoxR\"\n  # )\n\n  # # Ensure remotes is installed\n  # if (!requireNamespace(\"remotes\", quietly = TRUE)) {\n  #     install.packages(\"remotes\")\n  # }\n\n  # # Loop through each GitHub package\n  # for (pkg in github_packages) {\n  #     # Extract package name from the \"user/repo\" string\n  #     pkg_name &lt;- sub(\".*/\", \"\", pkg)\n\n  #     # Check if the package is installed\n  #     if (!requireNamespace(pkg_name, quietly = TRUE)) {\n  #         # If not installed, install the latest release from GitHub\n  #         remotes::install_github(paste0(pkg, \"@*release\"))\n  #     }\n  #     # Load the package\n  #     library(pkg_name, character.only = TRUE)\n  # }\n\n  # rm(github_packages, pkg, pkg_name)\n\n  # Custom Functions ----\n\n  `%ni%` &lt;- Negate(`%in%`)\n\n  geometric_mean &lt;- function(x) {\n    exp(mean(log(x[x &gt; 0]), na.rm = TRUE))\n  }\n\n  my_skim &lt;- skim_with(\n    numeric = sfl(\n      n = length,\n      min = ~ min(.x, na.rm = T),\n      p25 = ~ stats::quantile(., probs = .25, na.rm = TRUE, names = FALSE),\n      med = ~ median(.x, na.rm = T),\n      p75 = ~ stats::quantile(., probs = .75, na.rm = TRUE, names = FALSE),\n      max = ~ max(.x, na.rm = T),\n      mean = ~ mean(.x, na.rm = T),\n      geo_mean = ~ geometric_mean(.x),\n      sd = ~ stats::sd(., na.rm = TRUE),\n      hist = ~ inline_hist(., 5)\n    ),\n    append = FALSE\n  )\n}"
  },
  {
    "objectID": "posts/2025-11-04/2025-11-04.html#loading-necessary-packages",
    "href": "posts/2025-11-04/2025-11-04.html#loading-necessary-packages",
    "title": "Tidy Tuesday 2025-11-04: Lead concentration in Flint water samples in 2015",
    "section": "",
    "text": "My handy booster pack that allows me to install (if needed) and load my usual and favorite packages, as well as some helpful functions.\n\n\nCode\n# Packages ----------------------------------------------------------------\n\n{\n  # Install pak if it's not already installed\n  if (!requireNamespace(\"pak\", quietly = TRUE)) {\n    install.packages(\n      \"pak\",\n      repos = sprintf(\n        \"https://r-lib.github.io/p/pak/stable/%s/%s/%s\",\n        .Platform$pkgType,\n        R.Version()$os,\n        R.Version()$arch\n      )\n    )\n  }\n\n  # CRAN Packages ----\n  install_booster_pack &lt;- function(package, load = TRUE) {\n    # Loop through each package\n    for (pkg in package) {\n      # Check if the package is installed\n      if (!requireNamespace(pkg, quietly = TRUE)) {\n        # If not installed, install the package\n        pak::pkg_install(pkg)\n      }\n      # Load the package\n      if (load) {\n        library(pkg, character.only = TRUE)\n      }\n    }\n  }\n\n  if (file.exists('packages.txt')) {\n    packages &lt;- read.table('packages.txt')\n\n    install_booster_pack(package = packages$Package, load = FALSE)\n\n    rm(packages)\n  } else {\n    ## Packages ----\n\n    booster_pack &lt;- c(\n      ### IO ----\n      'fs',\n      'here',\n      'janitor',\n      'rio',\n      'tidyverse',\n      # 'data.table',\n      # 'mirai',\n      # 'targets',\n      # 'crew',\n\n      ### DB ----\n      # 'arrow',\n      # 'nanoparquet',\n      # 'duckdb',\n      # 'duckplyr',\n      # 'dbplyr',\n\n      ### EDA ----\n      'skimr',\n\n      ### Web ----\n      # 'rvest',\n      # 'polite',\n      # 'plumber',\n      # 'plumber2', #Still experimental\n      # 'httr2',\n\n      ### Plot ----\n      # 'paletteer',\n      # 'ragg',\n      'camcorder',\n      'esquisse',\n      # 'geofacet',\n      # 'patchwork',\n      # 'ggpubr', # Alternative to patchwork\n      # 'marquee',\n      # 'ggiraph',\n      # 'geomtextpath',\n      # 'ggpattern',\n      # 'ggbump',\n      # 'gghighlight',\n      # 'ggdist',\n      # 'ggforce',\n      # 'gghalves',\n      # 'ggtext',\n      # 'ggrepel', # Suggested for non-overlapping labels\n      # 'gganimate', # Suggested for animations\n      # 'ggsignif',\n      # 'ggTimeSeries',\n      # 'tidyheatmaps',\n      # 'ggdendro',\n      'ggstatsplot',\n\n      ### Modeling ----\n      'tidymodels',\n\n      ### Shiny ----\n      # 'shiny',\n      # 'bslib',\n      # 'DT',\n      # 'plotly',\n\n      ### Reporting ----\n      # 'quarto',\n      'gt',\n      'gtsummary',\n\n      ### Spatial ----\n      # 'sf',\n      # 'geoarrow',\n      # 'duckdbfs',\n      # 'duckspatial',\n      # 'ducksf',\n      # 'tidycensus', # Needs API\n      # 'mapgl',\n      # 'dataRetrieval', # Needs API\n      # 'StreamCatTools',\n\n      ### Misc ----\n      'tidytuesdayR'\n      # 'devtools',\n      # 'usethis',\n      # 'remotes'\n    )\n\n    # ! Change load flag to load packages\n    install_booster_pack(package = booster_pack, load = TRUE)\n    rm(install_booster_pack, booster_pack)\n  }\n\n  # GitHub Packages ----\n  # github_packages &lt;- c(\n  #     \"seanthimons/ComptoxR\"\n  # )\n\n  # # Ensure remotes is installed\n  # if (!requireNamespace(\"remotes\", quietly = TRUE)) {\n  #     install.packages(\"remotes\")\n  # }\n\n  # # Loop through each GitHub package\n  # for (pkg in github_packages) {\n  #     # Extract package name from the \"user/repo\" string\n  #     pkg_name &lt;- sub(\".*/\", \"\", pkg)\n\n  #     # Check if the package is installed\n  #     if (!requireNamespace(pkg_name, quietly = TRUE)) {\n  #         # If not installed, install the latest release from GitHub\n  #         remotes::install_github(paste0(pkg, \"@*release\"))\n  #     }\n  #     # Load the package\n  #     library(pkg_name, character.only = TRUE)\n  # }\n\n  # rm(github_packages, pkg, pkg_name)\n\n  # Custom Functions ----\n\n  `%ni%` &lt;- Negate(`%in%`)\n\n  geometric_mean &lt;- function(x) {\n    exp(mean(log(x[x &gt; 0]), na.rm = TRUE))\n  }\n\n  my_skim &lt;- skim_with(\n    numeric = sfl(\n      n = length,\n      min = ~ min(.x, na.rm = T),\n      p25 = ~ stats::quantile(., probs = .25, na.rm = TRUE, names = FALSE),\n      med = ~ median(.x, na.rm = T),\n      p75 = ~ stats::quantile(., probs = .75, na.rm = TRUE, names = FALSE),\n      max = ~ max(.x, na.rm = T),\n      mean = ~ mean(.x, na.rm = T),\n      geo_mean = ~ geometric_mean(.x),\n      sd = ~ stats::sd(., na.rm = TRUE),\n      hist = ~ inline_hist(., 5)\n    ),\n    append = FALSE\n  )\n}"
  },
  {
    "objectID": "posts/2025-11-04/2025-11-04.html#mdeq-data",
    "href": "posts/2025-11-04/2025-11-04.html#mdeq-data",
    "title": "Tidy Tuesday 2025-11-04: Lead concentration in Flint water samples in 2015",
    "section": "MDEQ data",
    "text": "MDEQ data\nI also remove the sample and notes column since I am just interested in the numerical data.\nThis also helps us examine the second proposed question from the repo.\n\nflint_mdeq %&gt;%\n  select(-notes, -sample) %&gt;%\n  my_skim(.)\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n71\n\n\nNumber of columns\n2\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nn\nmin\np25\nmed\np75\nmax\nmean\ngeo_mean\nsd\nhist\n\n\n\n\nlead\n0\n1.00\n71\n0\n2\n3\n6.5\n104\n7.31\n4.87\n14.35\n▇▁▁▁▁\n\n\nlead2\n2\n0.97\n71\n0\n2\n3\n6.0\n42\n5.72\n4.49\n8.34\n▇▁▁▁▁\n\n\n\n\n\n\nVT data\nFor the VT dataset as well:\n\nflint_vt %&gt;%\n  select(-sample) %&gt;%\n  my_skim(.)\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n271\n\n\nNumber of columns\n1\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nn\nmin\np25\nmed\np75\nmax\nmean\ngeo_mean\nsd\nhist\n\n\n\n\nlead\n0\n1\n271\n0.34\n1.58\n3.52\n9.05\n158\n10.65\n4.07\n21.56\n▇▁▁▁▁\n\n\n\n\n\n\n\nActionable-level Comparison\nAt the crux of this exercise is reproducing the determination if the samples collected by MDEQ with and without censoring of the data would cause a violation of existing state and federal law for lead contamination. For lead, the actionable level is 15 parts-per-billion (ppb).\n\n# Combine the three datasets into one tidy dataframe\ncombined_data &lt;- bind_rows(\n  flint_mdeq %&gt;%\n    mutate(dataset = \"MDEQ_uncensored\", lead = lead, .keep = 'none'),\n  flint_mdeq %&gt;%\n    mutate(dataset = \"MDEQ_censored\", lead = lead2, .keep = 'none'),\n  flint_vt %&gt;% mutate(dataset = \"VT\", lead = lead, .keep = 'none')\n) %&gt;%\n  filter(!is.na(lead)) # Remove NA values from the censored dataset\n\n\n# New skim function\n\nlead_skim &lt;- skim_with(\n  numeric = sfl(\n    n = length,\n    p90 = ~ stats::quantile(., probs = .9, na.rm = TRUE, names = FALSE),\n    max = ~ max(.x, na.rm = T)\n  ),\n  append = FALSE\n)\n\n# Running the new skim function that finds the 90th percentile to see if there was an exceedence\ncombined_data %&gt;%\n  group_by(dataset) %&gt;%\n  lead_skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n411\n\n\nNumber of columns\n2\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\ndataset\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\ndataset\nn_missing\ncomplete_rate\nn\np90\nmax\n\n\n\n\nlead\nMDEQ_censored\n0\n1\n69\n11.40\n42\n\n\nlead\nMDEQ_uncensored\n0\n1\n71\n18.00\n104\n\n\nlead\nVT\n0\n1\n271\n26.64\n158\n\n\n\n\n\nHere, we see that at the 90th percentile for the samples collected by MDEQ within the censored dataset it appears to pass (11.4 ppb), requiring no end-user notification or action. However, with the uncensored dataset, the 90th percentile becomes 18.0 ppb.\n\n\n\n\n\n\nImportant\n\n\n\nIt should be noted that the public health goal for lead is 0.00 ppb, as there is no safe amount of lead exposure.\nYou can read more about that here.\n\n\n\n\nComparison of datasets\nIf we want to see if multiple datasets are different from each other, we can run some simple statistical tests. As you requested, we’ll use an Analysis of Variance (ANOVA) test. This test will help us determine if there are any statistically significant differences between the means of our three groups:\n\nThe uncensored Michigan Department of Environment (MDEQ) data.\nThe “censored” MDEQ data (with two high-value samples removed).\nThe Virginia Tech (VT) citizen-collected data.\n\nWe will use the tidymodels framework to set up and run the ANOVA.\n\n# Define the model specification using tidymodels\nlm_spec &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\n# Define the recipe\nanova_recipe &lt;- recipe(lead ~ dataset, data = combined_data)\n\n# Create the workflow\nanova_workflow &lt;- workflow() %&gt;%\n  add_model(lm_spec) %&gt;%\n  add_recipe(anova_recipe)\n\n# Fit the workflow and extract the results\nanova_fit &lt;- fit(anova_workflow, data = combined_data)\n\n\n# Get the overall ANOVA table by extracting the engine fit\nanova(extract_fit_engine(anova_fit))\n\nAnalysis of Variance Table\n\nResponse: ..y\n           Df Sum Sq Mean Sq F value  Pr(&gt;F)  \ndataset     2   1653  826.45  2.3311 0.09848 .\nResiduals 408 144649  354.53                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Tidy the results to get the model coefficients\nbroom::tidy(anova_fit)\n\n# A tibble: 3 × 5\n  term                   estimate std.error statistic p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)                5.72      2.27     2.53   0.0119\n2 datasetMDEQ_uncensored     1.59      3.18     0.498  0.619 \n3 datasetVT                  4.92      2.54     1.94   0.0533\n\n# Or get a one-line summary of the overall model fit\nbroom::glance(anova_fit) %&gt;% glimpse()\n\nRows: 1\nColumns: 12\n$ r.squared     &lt;dbl&gt; 0.0112979\n$ adj.r.squared &lt;dbl&gt; 0.006451319\n$ sigma         &lt;dbl&gt; 18.82902\n$ statistic     &lt;dbl&gt; 2.331108\n$ p.value       &lt;dbl&gt; 0.09848121\n$ df            &lt;dbl&gt; 2\n$ logLik        &lt;dbl&gt; -1788.127\n$ AIC           &lt;dbl&gt; 3584.255\n$ BIC           &lt;dbl&gt; 3600.329\n$ deviance      &lt;dbl&gt; 144649.1\n$ df.residual   &lt;int&gt; 408\n$ nobs          &lt;int&gt; 411\n\n\nBefore we plot any data, we’ll set up a camcorder session to capture our plot(s) at the proper resolution. Not always needed, but helpful for iterating when making complex plots.\n\nif (!dir.exists(here::here('posts', '2025-11-04', 'output'))) {\n  dir.create(here::here('posts', '2025-11-04', 'output'))\n}\n\ngg_record(\n  here::here('posts', '2025-11-04', 'output'),\n  device = \"png\",\n  width = 10,\n  height = 7,\n  units = \"in\",\n  dpi = 320\n)\n\nThe very small p-value (p.value &lt; 0.05) for the dataset term indicates that there is a statistically significant difference between the mean lead levels of at least two of the groups.\nTo get a more intuitive visualization and a comprehensive statistical summary in one go, we can use the ggbetweenstats() function from the ggstatsplot package. This will create a plot and run the appropriate statistical tests automatically.\n\n# Calculate 90th percentile for each dataset\np90_data &lt;- combined_data %&gt;%\n  group_by(dataset) %&gt;%\n  summarize(p90 = quantile(lead, probs = 0.9, na.rm = TRUE))\n\nggbetweenstats(\n  data = combined_data,\n  x = dataset,\n  y = lead,\n  title = \"Distribution of Lead Concentration by Dataset\",\n  xlab = \"Dataset\",\n  ylab = \"Lead Concentration (ppb)\",\n  messages = FALSE\n) +\n  # Add 90th percentile lines for each dataset\n  geom_crossbar(\n    data = p90_data,\n    aes(x = dataset, y = p90, ymin = p90, ymax = p90),\n    width = 0.5,\n    color = \"blue\",\n    linetype = \"dashed\"\n  ) +\n  geom_text(\n    data = p90_data,\n    aes(x = dataset, y = p90, label = paste(\"90th:\", round(p90, 1), 'ppb')),\n    vjust = -0.5,\n    color = \"blue\",\n    nudge_x = 0.25\n  ) +\n  # Add layers to the ggplot object\n  geom_hline(\n    yintercept = 15,\n    linetype = \"dotted\",\n    color = \"red\"\n  ) +\n  annotate(\n    \"text\",\n    x = 0.5,\n    y = 15,\n    label = \"Action Level (15 ppb)\",\n    vjust = -0.5,\n    color = \"red\",\n    hjust = 0\n  ) +\n  ggrepel::geom_text_repel(\n    data = . %&gt;%\n      dplyr::filter(dataset == \"MDEQ_uncensored\", lead %in% c(20, 104)),\n    aes(label = paste(\"Removed:\", lead, \"ppb\")),\n    nudge_x = -0.4,\n    min.segment.length = 0\n  )"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Welcome to my blog. Here you’ll find my personal thoughts and explorations on various topics, mainly centered around data science, water resources, and risk assessment.\nDisclaimer: The views and opinions expressed on this blog are my own and do not necessarily reflect the views or positions of my employer.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Tuesday 2025-11-11\n\n\n\ntidytuesday\n\n\n\n\n\n\n\n\n\nNov 11, 2025\n\n\nSean Thimons\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Tuesday 2025-11-04: Lead concentration in Flint water samples in 2015\n\n\n\ntidytuesday\n\n\n\n\n\n\n\n\n\nNov 4, 2025\n\n\nSean Thimons\n\n\n\n\n\n\n\n\n\n\n\n\nMy First Post\n\n\n\nwelcome\n\nnews\n\n\n\n\n\n\n\n\n\nJan 1, 1970\n\n\nSean Thimons\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "volunteer.html",
    "href": "volunteer.html",
    "title": "Volunteering",
    "section": "",
    "text": "I currently volunteer in my local community in a variety of ways!\n\nCincinnati Machine Learning Meetup group\nI serve as a meeting organize, co-host, and occasional guest lecturer for the Cincinnati Machine Learning Meetup group, where we have a rotating schedule of technical talks, practical demonstrations, and social meetups on all things involving machine learning and artificial intelligence.\nI’ve given talks on exploratory data analysis and time-series analysis using R as well as machine learning on complex data sets (also in R).\nSome of my work can be found here: FracFocus Curation\n\n\n2024 Housing Stabilization Hackathon\nI also participated in the 2024 Housing Stabilization Hackathon competition with other data scientists, programmers, market research professionals, real estate investors, and community development advocates to propose new ways of reducing evictions in Cincinnati.\nOur team (with Serge Doumit, Mahmoud Shobair) proposed a novel method of early intervention by using data from housing and other social services to predict relative risk of eviction before an individual was in a housing crisis situation. Our method utilized national, state, and localized datasets to identify large-scale and local characteristics that drive evictions across the city via a random forest model which identified several prominent that predominately drove eviction homelessness rates here in Cincinnati. We ended winning “Best Presentation”. Not bad for three days of work!\nYou can read more here: Hackathon"
  }
]